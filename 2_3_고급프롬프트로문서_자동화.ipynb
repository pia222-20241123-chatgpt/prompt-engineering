{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zd9_ZEB_pyXV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- transformer 구조  : 자연어 처리에서 주로 사용되는 딥러닝 모델\n",
        "  - Selft-Attention\n",
        "    - 입력 데이터의 각 요소가 서로 어떤 관계를 가지는지 파악\n",
        "    - 이를 통해 단어간의 문맥정보를 효육적으로 이해하고 긴 문장에서 중요한 요소를 찾아낼수 있다\n",
        "  - Multi-Head Attention\n",
        "    - 여러개의 어텐션 병렬로 사용해서 다양한 문맥적 정보를 학습\n",
        "  - Feed-Forward Network(FFN)\n",
        "    - 각 위치에서 데이터를 처리하고 비선형 변환을 통해 모델의 표현력을 높임\n",
        "  - Positional Encoding\n",
        "    - Transformer 는 순서 정보를 가지고 있지 않기때문에 입력 데이터에 위치정보를 추가\n",
        "  - Encoder-Decode 구조\n",
        "    - Encoder : 입력문장의 의미를 추출  -> 수치화\n",
        "    - Decoder : 추출된 의미를 바탕으로 요약문이나 번역 결과를생성\n",
        "    \n"
      ],
      "metadata": {
        "id": "uV4h_T91p25i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y_nUMaQFrPMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}