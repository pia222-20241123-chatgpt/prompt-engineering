{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "나만의 chat 봇 만들기\n",
        "\n",
        "https://openai.com/api/"
      ],
      "metadata": {
        "id": "YnzB8wSa4uiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. openai 에 가입해서 token을 발행받는다... 무료는 사용에 한계가 있음\n",
        "  - 무료사용을 하려고 해도 카드등록 필수\n",
        "2. 허깅페이스 Hugging Face Transformers  "
      ],
      "metadata": {
        "id": "I9iw-gf045z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>')\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "\n",
        "def chatboat(text):\n",
        "  input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "  gen_ids = model.generate(input_ids,\n",
        "                            max_length=128,\n",
        "                            repetition_penalty=2.0,\n",
        "                            pad_token_id=tokenizer.pad_token_id,\n",
        "                            eos_token_id=tokenizer.eos_token_id,\n",
        "                            bos_token_id=tokenizer.bos_token_id,\n",
        "                            use_cache=True)\n",
        "  generated = tokenizer.decode(gen_ids[0])\n",
        "\n",
        "  print(generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5DNmTZSt7zn2",
        "outputId": "76413fa2-18e1-42b3-c3b6-bdd947ae95f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  text = input(\"질문을 입력하세요 쳇봇종료는 q를 누르세요: \")\n",
        "  if text.strip() == 'q':\n",
        "    print(\"챗봇 종료\")\n",
        "    break\n",
        "  chatboat(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vp_Pqor19FYH",
        "outputId": "70f99431-ccd8-472d-a244-b625b56ced7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문을 입력하세요 쳇봇종료는 q를 누르세요: 효과적인 다이어트 방법 알려줘\n",
            "효과적인 다이어트 방법 알려줘야 한다.\n",
            "또한 식이요법과 운동요법을 병행하는 것이 좋다.\n",
            "특히, 체지방 감소에 도움이 되는 음식으로는 콩나물, 두부 등이 있다.\n",
            "콩나물에는 비타민 C가 풍부해 변비 예방과 혈당 조절에도 도움을 준다.\n",
            "두부 역시 식이섬유와 무기질이 풍부한 식품으로 콜레스테롤을 낮춰주는 효과가 있어 비만 예방을 위한 좋은 음식으로 꼽힌다.\n",
            "이외도 두부, 김치, 된장, 고추장 등 다양한 발효식품은 지방 분해효소를 증가시켜 체중 감량에 효과적이다.\n",
            "하지만 이러한 음식을 섭취할 경우 오히려 살이 찌는 원인이 될 수 있으므로 주의해야 한다.</d> 지난달 30일 오후 서울 종로구\n",
            "질문을 입력하세요 쳇봇종료는 q를 누르세요: ㅂ\n",
            "ᄇᄀᄒ\n",
            "#먹스타그램<unk>naver.com/musicial</d> 오늘은 내일도 화이팅!!\n",
            "오늘의 포스팅을 마무리하고 싶어서~^^ \n",
            "이번 주말엔 또 다른 이벤트가 기다리고 있어요 ~?\n",
            "저는 이번주 토요일부터 일요일까지 매일매일 참여합니다ᄏ.\n",
            "저희는 매주 월,수,금 요일에 참여할 수 있는 이벤트인데요,\n",
            "토욜에 진행되니까 더더욱 많은 분들이 참여해 주시길 바랍니다\n",
            "제가 좋아하는 캐릭터인 ``아빠는 왜? 아냐고 물어보시면 안돼요?\n",
            "\n",
            "질문을 입력하세요 쳇봇종료는 q를 누르세요: q\n",
            "챗봇 종료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PDF문서를 text 로 추출하기(변환)"
      ],
      "metadata": {
        "id": "Ri13ji8RANPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIoSGaHVAJ9-",
        "outputId": "062ada8f-3b5c-471b-e9e7-691df1f134ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.14-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.14-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.24.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF 라이브러리 임포트\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    # PDF 파일 열기\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    # PDF 문서에서 텍스트 추출\n",
        "    full_text = \"\"\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc.load_page(page_num)  # 각 페이지 로드\n",
        "        full_text += page.get_text(\"text\")  # 페이지에서 텍스트 추출\n",
        "\n",
        "    return full_text\n",
        "\n",
        "# PDF 문서에서 텍스트 추출\n",
        "pdf_path = \"/content/drive/MyDrive/필수업무_종사자_업무매뉴얼.pdf\"  # PDF 파일 경로(자신의 구글드라이브에있는 파일경로)\n",
        "manual_text = extract_text_from_pdf(pdf_path)\n",
        "print(manual_text[:1000])  # 처음 1000자 출력 (전체 출력은 너무 길어질 수 있습니다)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6Q7aQvCM9I-t",
        "outputId": "bfccf88d-59fe-4f1a-c85e-6f49e569e392"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01\n",
            "1. 재난과 필수노동에 대한 인식변화\n",
            "2. 도입배경\n",
            "3. 주요개념\n",
            "4. 유사제도와 비교\n",
            "5. 코로나 관련 해외대응 사례\n",
            "6. 관련법령 주요내용\n",
            "필수업무 종사자 \n",
            "보호･지원제도\n",
            "02\n",
            "1. 총괄\n",
            "2. 고용노동부\n",
            "3. 지방자치단체\n",
            "4. 중앙재난안전대책본부와 협조\n",
            "5. 지원(실무)위원회의 전문성 확대\n",
            "추진체계\n",
            "03\n",
            "1. 개요\n",
            "2. 실태조사 항목\n",
            "3. 조사방식 및 범위\n",
            "4. 조사실시 및 조사결과의 활용\n",
            "5. 실태조사 후 조치\n",
            "실태조사\n",
            "04\n",
            "1. 정책환경 및 기본원칙\n",
            "2. 상황모니터링\n",
            "3. 지원위원회 소집\n",
            "4. 지원계획 수립\n",
            "5. 지원계획의 시행 및 점검\n",
            "6. 중앙-광역-기초 자치단체간의 협조\n",
            "지원계획 \n",
            "수립･시행\n",
            "05\n",
            "1. 평가목적\n",
            "2. 평가항목\n",
            "3. 평가절차 \n",
            "4. 포상의 실시\n",
            "평가･포상\n",
            "06\n",
            "1. 필수업무 및 종사자 판단기준\n",
            "2. 실태조사\n",
            "3. 적용순위\n",
            "4. 지원위원회 개최 시기\n",
            "5. 적용대상\n",
            "6. 지역위원회 운영\n",
            "필수업무 관련\n",
            "Q&A\n",
            "07\n",
            "❙「필수업무종사자법」\n",
            "❙「재난안전법」\n",
            "❙국가위기관리기본지침(대통령 훈령 제388호)\n",
            "❙「필수업무 지정 및 종사자 지원위원회」 운영세칙\n",
            "❙필수업무 종사자 보호･지원 조례 관련 안내 사항\n",
            "❙재난유형별 관련법령 현황\n",
            "❙재난 및 사고유형별 주관기관 및 소관부서 현황\n",
            "부록\n",
            "필수업무 종사자 \n",
            "보호･지원 제도\n",
            "1. 재난과 필수노동에 대한 인식변화\n",
            "2. 도입배경\n",
            "3. 주요개념\n",
            "4. 유사제도와 비교\n",
            "5. 코로나 관련 해외대응 사례\n",
            "6. 관련법령 주요내용\n",
            "7. 정책환경 및 지원계획의 기본원칙\n",
            "2 필수업무 종사자 업무매뉴얼\n",
            "1. 재난과 필수노동에 대한 인식변화\n",
            "가. 필수업무 인식의 변화\n",
            "코로나바이러스 감염증-19(COVID-19, 이하 ‘코로나19’라 함)은 그동안 \n",
            "우리 사회의 일상 유지를 위해 보이지 않는 곳에서 끊임없이 움직이고 있던 \n",
            "노동을 수면 위로 드러냄(이승윤 외, 석재은 등)\n",
            "- 많은 사람이 일상에서 ‘멈춤’을 경험하자 멈추지 못하는 노동이 보이고 \n",
            "들리기 시작하였고\n",
            "- 이러한 종사자들이 그동안 충분히 관심을 받지 못하고 드러나\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "import fitz  # PyMuPDF 라이브러리 임포트\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>')\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "\n",
        "# 메뉴얼 파일 로드 (PDF에서 텍스트 추출)\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    # PDF 파일 열기\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    # PDF 문서에서 텍스트 추출\n",
        "    full_text = \"\"\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc.load_page(page_num)  # 각 페이지 로드\n",
        "        full_text += page.get_text(\"text\")  # 페이지에서 텍스트 추출\n",
        "\n",
        "    return full_text\n",
        "\n",
        "# 메뉴얼을 로드하여 학습\n",
        "pdf_path = \"/content/drive/MyDrive/필수업무_종사자_업무매뉴얼.pdf\"  # PDF 파일 경로\n",
        "manual_text = extract_text_from_pdf(pdf_path)  # 메뉴얼 텍스트\n",
        "\n",
        "# 메뉴얼 텍스트의 길이가 너무 길면 일부만 사용하기\n",
        "MAX_INPUT_LENGTH = 1024  # 모델에 입력할 최대 길이 (1024로 설정)\n",
        "\n",
        "# 모델에 메뉴얼 내용을 한번 학습하도록 설정 (학습이 아니라 입력을 제공하는 방식)\n",
        "def generate_manual_response(question):\n",
        "    # 텍스트 길이가 너무 길 경우 일부만 사용\n",
        "    truncated_manual_text = manual_text[:MAX_INPUT_LENGTH]\n",
        "\n",
        "    # 사용자 질문과 메뉴얼 내용을 결합\n",
        "    input_text = f\"메뉴얼 내용: {truncated_manual_text}\\nQ: {question}\\nA:\"\n",
        "\n",
        "    # 질문 텍스트 토큰화\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt', truncation=True, max_length=MAX_INPUT_LENGTH)\n",
        "\n",
        "    # 모델을 사용하여 답변 생성\n",
        "    gen_ids = model.generate(input_ids,\n",
        "                             max_new_tokens=100,  # 생성되는 답변의 최대 길이를 100으로 설정\n",
        "                             repetition_penalty=2.0,\n",
        "                             pad_token_id=tokenizer.pad_token_id,\n",
        "                             eos_token_id=tokenizer.eos_token_id,\n",
        "                             bos_token_id=tokenizer.bos_token_id,\n",
        "                             use_cache=True)\n",
        "\n",
        "    # 생성된 텍스트를 디코딩하여 출력\n",
        "    generated_text = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # \"A:\" 이후의 답변 부분만 반환\n",
        "    answer = generated_text.split('A:')[1].strip() if 'A:' in generated_text else generated_text\n",
        "    return answer\n",
        "\n",
        "# 대화 시작\n",
        "while True:\n",
        "    user_input = input(\"질문을 입력하세요 (종료하려면 'exit' 입력): \")\n",
        "    if user_input.lower() in ['exit', 'quit', '종료']:\n",
        "        print(\"챗봇 종료.\")\n",
        "        break\n",
        "    bot_response = generate_manual_response(user_input)\n",
        "    print(f\"챗봇: {bot_response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i-1PwEH_BkSl",
        "outputId": "0e1ffe8b-c768-43ae-ee10-0be55f1035ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문을 입력하세요 (종료하려면 'exit' 입력): 필수 업무 종사자의 정의\n",
            "챗봇: 의무적으로 필요한 업무를 수행하는 사람입니다.\n",
            "(예: 보건의료인, 간호사, 사회복지사 등) - 이 경우 반드시 필요해야 하는 업무는?\n",
            "A. (예 : 의료인 또는 요양시설 근무자, 간병인이 아닌 자로서 ) , 그리고 ▲ 해당 직무의 수행으로 인해 불가피하게 발생하는 불가피한 경우를 제외하고는 ▷ 이에 준하는 일을 해야 합니다.\n",
            "▲ 이를 위한 최소한의 요건으로서 ▶ 이는 필수적으로 갖추어야 할 기본적인 조건이다.\n",
            "△ 이와 같은 의무를 이행하기 위해서는 최소 1년 이상의 시간이 필요합니다.\n",
            "또한, A는 기본적으로 요구되는 업무에 대해선\n",
            "질문을 입력하세요 (종료하려면 'exit' 입력): 필수 업무종사자의 자격\n",
            "챗봇: 의무적으로 필요한 경우입니다.\n",
            "(무조건 필요하다).\n",
            "A. (중요한 것은 ) 반드시 필요합니다.\n",
            "그렇지만 꼭 필요하지 않다\n",
            "거나 불필요하다고 생각하시는 분들은?\n",
            "‘자격’ 또는 ‘무료’라고 하는 것이 아닙니다.\n",
            "다만 중요한 것을 제외하고는요.\n",
            "예를 들어 어떤 일을 하고 있는지, 또 다른 업무를 수행하고 있는지 등을 알고 싶다면.\n",
            "“○ ○○”이라고 하면 됩니다.\n",
            "하지만 이 경우에는 “△ ○”라고 해야 합니다.\n",
            "또한 해당 업무는 무엇인지, 그리고 어떻게 일하고 있는지를 알아야 해요.\n",
            "그리고 그에 따른\n",
            "질문을 입력하세요 (종료하려면 'exit' 입력): exit\n",
            "챗봇 종료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체문장을 학습"
      ],
      "metadata": {
        "id": "Txx7MDpyHIpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "import fitz  # PyMuPDF 라이브러리 임포트\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>')\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "\n",
        "# 메뉴얼 파일 로드 (PDF에서 텍스트 추출)\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    # PDF 파일 열기\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    # PDF 문서에서 텍스트 추출\n",
        "    full_text = \"\"\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc.load_page(page_num)  # 각 페이지 로드\n",
        "        full_text += page.get_text(\"text\")  # 페이지에서 텍스트 추출\n",
        "\n",
        "    return full_text\n",
        "\n",
        "# 메뉴얼을 로드하여 학습\n",
        "pdf_path = \"/content/drive/MyDrive/필수업무_종사자_업무매뉴얼.pdf\"  # PDF 파일 경로\n",
        "manual_text = extract_text_from_pdf(pdf_path)  # 메뉴얼 텍스트\n",
        "\n",
        "# 모델에 입력할 최대 길이 (토큰 기준)\n",
        "MAX_INPUT_LENGTH = 1024  # 모델이 한 번에 처리할 수 있는 토큰의 최대 길이\n",
        "\n",
        "# 슬라이딩 윈도우 방식으로 텍스트 나누기\n",
        "def sliding_window_process(text, max_length):\n",
        "    # 텍스트를 윈도우 크기에 맞게 나누기\n",
        "    window_size = max_length - 2  # 토큰화 시, EOS와 BOS 토큰을 제외한 크기\n",
        "    overlap = 200  # 슬라이딩 윈도우 겹침 크기 (겹치는 부분으로 연속성을 유지)\n",
        "\n",
        "    start = 0\n",
        "    chunks = []\n",
        "\n",
        "    while start < len(text):\n",
        "        end = min(start + window_size, len(text))\n",
        "        chunk = text[start:end]\n",
        "        chunks.append(chunk)\n",
        "        start = end - overlap  # 겹치는 부분을 설정하여 연속성을 유지\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# 메뉴얼 텍스트를 슬라이딩 윈도우 방식으로 나누기\n",
        "chunks = sliding_window_process(manual_text, MAX_INPUT_LENGTH)\n",
        "\n",
        "# 슬라이딩 윈도우 방식으로 각 부분에 대해 모델에서 답변 생성\n",
        "def generate_manual_response(question):\n",
        "    input_text = f\"Q: {question}\\nA:\"\n",
        "    responses = []\n",
        "\n",
        "    # 각 청크를 모델에 입력하여 답변 생성\n",
        "    for chunk in chunks:\n",
        "        full_input_text = f\"메뉴얼 내용: {chunk}\\n{input_text}\"\n",
        "        input_ids = tokenizer.encode(full_input_text, return_tensors='pt', truncation=True, max_length=MAX_INPUT_LENGTH)\n",
        "\n",
        "        gen_ids = model.generate(input_ids,\n",
        "                                 max_new_tokens=100,  # 생성되는 답변의 최대 길이를 100으로 설정\n",
        "                                 repetition_penalty=2.0,\n",
        "                                 pad_token_id=tokenizer.pad_token_id,\n",
        "                                 eos_token_id=tokenizer.eos_token_id,\n",
        "                                 bos_token_id=tokenizer.bos_token_id,\n",
        "                                 use_cache=True)\n",
        "\n",
        "        generated_text = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        # \"A:\" 이후의 답변 부분만 추출하여 추가\n",
        "        answer = generated_text.split('A:')[1].strip() if 'A:' in generated_text else generated_text\n",
        "        responses.append(answer)\n",
        "\n",
        "    # 여러 부분에서 나온 답변들을 합침\n",
        "    full_answer = \" \".join(responses)\n",
        "    return full_answer\n",
        "\n",
        "# 대화 시작\n",
        "while True:\n",
        "    user_input = input(\"질문을 입력하세요 (종료하려면 'exit' 입력): \")\n",
        "    if user_input.lower() in ['exit', 'quit', '종료']:\n",
        "        print(\"챗봇 종료.\")\n",
        "        break\n",
        "    bot_response = generate_manual_response(user_input)\n",
        "    print(f\"챗봇: {bot_response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_dP15TqC4Al",
        "outputId": "b24dbbee-5d76-4e9d-b103-0ad7bde6409e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HnvMYFmgHNXs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}